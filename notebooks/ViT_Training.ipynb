{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvWq/ICyPtKPtV1PgpaAAd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a349ca65034944a59c337168f8ed3d17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e8d555b7fc147cfbff154326701a434","IPY_MODEL_156885203ebe47c1a0f8382b270f6430","IPY_MODEL_2322ab5927bd41be978c09f34d548902"],"layout":"IPY_MODEL_9334bfb501124d9185e324ce4c112b24"}},"3e8d555b7fc147cfbff154326701a434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ea23af41484247a61f6f10c2add01b","placeholder":"​","style":"IPY_MODEL_7e903fca54274b979cb9174b596abb9a","value":"Epoch 6: 100%"}},"156885203ebe47c1a0f8382b270f6430":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ce91d5f9274b99b3be60513906fd77","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72aedb80636e4e56acf8deb6ec16d2d3","value":1}},"2322ab5927bd41be978c09f34d548902":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54cee30c5b5a4bf5bb8d863c9d24022b","placeholder":"​","style":"IPY_MODEL_94da874064be446db79eae00f4337cf7","value":" 529/529 [1:02:39&lt;00:00,  0.14it/s, v_num=3, train_loss=0.612]"}},"9334bfb501124d9185e324ce4c112b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e7ea23af41484247a61f6f10c2add01b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e903fca54274b979cb9174b596abb9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09ce91d5f9274b99b3be60513906fd77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72aedb80636e4e56acf8deb6ec16d2d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54cee30c5b5a4bf5bb8d863c9d24022b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94da874064be446db79eae00f4337cf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b1f50a244a0436d8dcd9c957d20331e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_640ce9a3215c4c87b43865ec3b2fdf9d","IPY_MODEL_574e04a16dd04bdea2b21d5772942d66","IPY_MODEL_38cc69c4ef484e8a89c815ff26d2f751"],"layout":"IPY_MODEL_05b1d60d9a2d45ca86cb552e4c786be7"}},"640ce9a3215c4c87b43865ec3b2fdf9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926d49adada94f84bf0200936872a7d3","placeholder":"​","style":"IPY_MODEL_45e977b6d4e8424bbee8c93ffca4f5f9","value":"Testing DataLoader 0: 100%"}},"574e04a16dd04bdea2b21d5772942d66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88eb394c079647a897d6911697e73baf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c348d66f5b4b415dbccc1754f0695529","value":1}},"38cc69c4ef484e8a89c815ff26d2f751":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10bc3f1eabe24cbeb75b6fcf9ac233b4","placeholder":"​","style":"IPY_MODEL_899b313708b4471981a5b76badef8fdc","value":" 25/25 [04:46&lt;00:00,  0.09it/s]"}},"05b1d60d9a2d45ca86cb552e4c786be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"926d49adada94f84bf0200936872a7d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e977b6d4e8424bbee8c93ffca4f5f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88eb394c079647a897d6911697e73baf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c348d66f5b4b415dbccc1754f0695529":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10bc3f1eabe24cbeb75b6fcf9ac233b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"899b313708b4471981a5b76badef8fdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZzNvTH_SuJR","executionInfo":{"status":"ok","timestamp":1763525647293,"user_tz":-330,"elapsed":9175,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"41dc7cc0-ce5e-4102-d814-96e484ea83c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.8.0+cu126)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n","Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n","Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n","Downloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.15.2 pytorch-lightning-2.5.6 torchmetrics-1.8.2\n","Dependencies installed. Please re-run the previous code block (Code Block 1) now.\n"]}],"source":["# %%\n","# Install PyTorch Lightning and timm\n","!pip install pytorch-lightning timm\n","\n","print(\"Dependencies installed. Please re-run the previous code block (Code Block 1) now.\")"]},{"cell_type":"code","source":["# %%\n","import torch\n","import torch.nn as nn\n","import pytorch_lightning as pl\n","import timm\n","import json\n","import os\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from google.colab import drive\n","# from project_data_module import YourDataModule # Keep this commented for now\n","\n","# --- 1. Mount Google Drive ---\n","PROJECT_ROOT = '/content/drive/MyDrive/Hybrid_Project'\n","print(f\"Project root set to: {PROJECT_ROOT}\")\n","\n","# Mount Drive\n","drive.mount('/content/drive')\n","\n","# Create necessary directories\n","os.makedirs(os.path.join(PROJECT_ROOT, 'models'), exist_ok=True)\n","os.makedirs(os.path.join(PROJECT_ROOT, 'results'), exist_ok=True)\n","\n","print(\"Google Drive mounted and directories checked.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tm8kI2FUON-","executionInfo":{"status":"ok","timestamp":1763526324494,"user_tz":-330,"elapsed":150820,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"a98118ac-836c-4c66-a5c9-5fce24734dbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Project root set to: /content/drive/MyDrive/Hybrid_Project\n","Mounted at /content/drive\n","Google Drive mounted and directories checked.\n"]}]},{"cell_type":"code","source":["# Add this line at the absolute top of the cell (no preceding spaces or lines)\n","%%writefile /content/drive/MyDrive/Hybrid_Project/project_data_module.py\n","\n","import os\n","import torch\n","import logging\n","import pytorch_lightning as pl\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets\n","from torchvision.datasets.folder import default_loader\n","from PIL import UnidentifiedImageError\n","# Note: PIL/Image is implicitly used by default_loader\n","\n","# Configure logging to see which files are skipped\n","logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')\n","\n","# --- 1. Robust Dataset Wrapper ---\n","class RobustImageFolder(Dataset):\n","    \"\"\"A wrapper for ImageFolder that skips corrupted images.\"\"\"\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","        self.loader = default_loader\n","        self.transform = dataset.transform\n","\n","    def __getitem__(self, index):\n","        path, target = self.dataset.samples[index]\n","\n","        try:\n","            # Load the image using the default loader\n","            sample = self.loader(path)\n","\n","            if self.transform is not None:\n","                sample = self.transform(sample)\n","\n","            return sample, target\n","\n","        except (UnidentifiedImageError, OSError) as e:\n","            # If the image is corrupted or cannot be read, log and get a random new index\n","            logging.warning(f\"Skipping corrupted file: {path}\")\n","\n","            # Get a random new index to fetch a valid sample instead\n","            new_index = torch.randint(0, len(self), (1,)).item()\n","            return self.__getitem__(new_index) # Recursively call to get a valid sample\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","\n","# --- 2. Transformations ---\n","IMAGE_TRANSFORM = transforms.Compose([\n","    transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","# --- 3. HybridDataModule ---\n","class HybridDataModule(pl.LightningDataModule):\n","    def __init__(self, data_dir: str, batch_size: int = 32):\n","        super().__init__()\n","        # Use the passed data_dir argument\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","        self.transform = IMAGE_TRANSFORM\n","\n","        self.train_dir = os.path.join(self.data_dir, 'train')\n","        self.val_dir = os.path.join(self.data_dir, 'valid')\n","        self.test_dir = os.path.join(self.data_dir, 'test')\n","\n","\n","    def setup(self, stage=None):\n","        try:\n","            print(\"Loading training dataset (Robust)...\")\n","            # Load base ImageFolder, then wrap it with the RobustImageFolder\n","            base_train_dataset = datasets.ImageFolder(root=self.train_dir, transform=self.transform)\n","            self.train_dataset = RobustImageFolder(base_train_dataset)\n","\n","            print(\"Loading validation dataset (Robust)...\")\n","            base_val_dataset = datasets.ImageFolder(root=self.val_dir, transform=self.transform)\n","            self.val_dataset = RobustImageFolder(base_val_dataset)\n","\n","            base_test_dataset = datasets.ImageFolder(root=self.test_dir, transform=self.transform)\n","            self.test_dataset = RobustImageFolder(base_test_dataset)\n","\n","            self.num_classes = len(base_train_dataset.classes)\n","            print(f\"Dataset loaded successfully. Found {self.num_classes} classes.\")\n","\n","        except Exception as e:\n","            print(f\"⚠️ Warning: Failed to load REAL data (Exception during setup): {e}. Creating DUMMY data.\")\n","            self.num_classes = 3\n","            # DUMMY DATA CREATION (This will only run if an exception occurs)\n","            self.train_dataset = [(torch.randn(3, 224, 224), torch.randint(0, self.num_classes, (1,)).item()) for _ in range(100)]\n","            self.val_dataset = [(torch.randn(3, 224, 224), torch.randint(0, self.num_classes, (1,)).item()) for _ in range(20)]\n","            self.test_dataset = [(torch.randn(3, 224, 224), torch.randint(0, self.num_classes, (1,)).item()) for _ in range(20)]\n","\n","\n","    def train_dataloader(self):\n","        # FIX: Setting num_workers=0 to prevent multiprocessing crash\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0)\n","\n","    def val_dataloader(self):\n","        # FIX: Setting num_workers=0\n","        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=0)\n","\n","    def test_dataloader(self):\n","        # FIX: Setting num_workers=0\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=0)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkOAmguG2Xy6","executionInfo":{"status":"ok","timestamp":1763530140061,"user_tz":-330,"elapsed":66,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"7827062d-a1f4-4565-efd7-c495947bca78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Hybrid_Project/project_data_module.py\n"]}]},{"cell_type":"code","source":["# %%\n","# Fix for ModuleNotFoundError when importing local files from Drive\n","import sys\n","\n","# PROJECT_ROOT was defined in Code Block 1\n","if PROJECT_ROOT not in sys.path:\n","    sys.path.append(PROJECT_ROOT)\n","    print(f\"Added {PROJECT_ROOT} to sys.path for local module imports.\")\n","else:\n","    print(f\"{PROJECT_ROOT} already in sys.path.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tt8gC3qsa6Sh","executionInfo":{"status":"ok","timestamp":1763530166712,"user_tz":-330,"elapsed":13,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"2750b648-448c-49eb-baf3-701093216b8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Hybrid_Project already in sys.path.\n"]}]},{"cell_type":"code","source":["# %%\n","# Force a reload of the project_data_module file to ensure the RobustImageFolder fix is active\n","import importlib\n","try:\n","    import project_data_module\n","    importlib.reload(project_data_module)\n","    print(\"Forced reload of project_data_module.\")\n","except ImportError:\n","    print(\"project_data_module not found, continuing...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ncdZavmDj3HM","executionInfo":{"status":"ok","timestamp":1763530169153,"user_tz":-330,"elapsed":41,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"bf5daf43-b497-4f14-b88f-3ab214290b06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Forced reload of project_data_module.\n"]}]},{"cell_type":"code","source":["# %%\n","# -----------------------------------------------------------\n","# 2. Load DataModule\n","# -----------------------------------------------------------\n","\n","import torchmetrics\n","\n","# Assuming 'project_data_module.py' is in the PROJECT_ROOT folder\n","from project_data_module import HybridDataModule\n","import torch\n","import torch.nn as nn\n","import pytorch_lightning as pl\n","import timm\n","\n","# Since 'train', 'test', and 'valid' are directly in 'data/'\n","DATA_PATH = os.path.join(PROJECT_ROOT, 'data')\n","\n","# Initialize the DataModule instance\n","dm = HybridDataModule(\n","    data_dir=DATA_PATH,\n","    batch_size=32,\n","    # image_size=224 is handled by your internal transforms\n",")\n","\n","# Run setup to prepare data splits (this will determine NUM_CLASSES)\n","dm.setup('fit')\n","\n","# Get the confirmed number of classes\n","NUM_CLASSES = dm.num_classes\n","\n","print(f\"Data Path defined: {DATA_PATH}\")\n","print(f\"Number of Classes obtained from DataModule: {NUM_CLASSES}\")\n","\n","\n","# %%\n","# -----------------------------------------------------------\n","# 3. Define ViT Model (Frozen Backbone)\n","# -----------------------------------------------------------\n","\n","class ViTModel(pl.LightningModule):\n","    def __init__(self, num_classes: int):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.num_classes = num_classes\n","\n","        # Load ViT-Small (ViT-Small/16) from timm\n","        self.backbone = timm.create_model(\n","            'vit_small_patch16_224',\n","            pretrained=True,\n","            num_classes=0 # Set to 0 to remove the default classification head\n","        )\n","\n","        # --- Freeze Backbone ---\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","\n","        # Feature dimension for vit_small_patch16_224 is 768\n","        feature_dim = self.backbone.num_features\n","\n","        # --- Add Classifier Head ---\n","        self.classifier = nn.Sequential(\n","            nn.Linear(feature_dim, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","        # Metrics for testing (Task 3)\n","        self.test_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n","        # We use average='none' to get the class-wise results needed for the log\n","        self.test_f1 = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='none')\n","\n","    def forward(self, x):\n","        features = self.backbone(x)\n","        return self.classifier(features)\n","\n","    # --- Training Step ---\n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.criterion(logits, y)\n","        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n","        return loss\n","\n","    # --- Test Step (Required for Task 3) ---\n","    def test_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.criterion(logits, y)\n","        preds = torch.argmax(logits, dim=1)\n","\n","        self.test_accuracy.update(preds, y)\n","        self.test_f1.update(preds, y)\n","        self.log('test_loss', loss, on_step=False, on_epoch=True)\n","\n","    def on_test_epoch_end(self):\n","        # Calculate and log final metrics at the end of the test epoch\n","        self.log('accuracy', self.test_accuracy.compute())\n","\n","        # Calculate class-wise results\n","        class_f1 = self.test_f1.compute()\n","        for i in range(self.num_classes):\n","             self.log(f'class_{i}_f1', class_f1[i], on_epoch=True)\n","\n","        # Reset metrics for next use\n","        self.test_accuracy.reset()\n","        self.test_f1.reset()\n","\n","    def configure_optimizers(self):\n","        # Only optimizing the un-frozen parameters (the classifier head)\n","        optimizer = torch.optim.Adam(self.classifier.parameters(), lr=1e-3)\n","        return optimizer\n","\n","# Initialize the model\n","vit_model = ViTModel(num_classes=NUM_CLASSES)\n","\n","print(\"-\" * 30)\n","print(f\"ViT Model initialized with {NUM_CLASSES} classes.\")\n","print(f\"Backbone requires_grad status (should be False): {vit_model.backbone.parameters().__next__().requires_grad}\")\n","print(\"Classifier requires_grad status (should be True):\", vit_model.classifier.parameters().__next__().requires_grad)\n","print(\"-\" * 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOdjV5H6XZ9b","executionInfo":{"status":"ok","timestamp":1763530176714,"user_tz":-330,"elapsed":1068,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"2b036498-ccd5-4778-95ac-1a09907eff64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading training dataset (Robust)...\n","Loading validation dataset (Robust)...\n","Dataset loaded successfully. Found 3 classes.\n","Data Path defined: /content/drive/MyDrive/Hybrid_Project/data\n","Number of Classes obtained from DataModule: 3\n","------------------------------\n","ViT Model initialized with 3 classes.\n","Backbone requires_grad status (should be False): False\n","Classifier requires_grad status (should be True): True\n","------------------------------\n"]}]},{"cell_type":"code","source":["# %%\n","# -----------------------------------------------------------\n","# 4. Initialize Trainer & Run Training (5–7 epochs)\n","# -----------------------------------------------------------\n","\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","import torch\n","\n","# Define the path for saving model weights\n","MODEL_SAVE_DIR = os.path.join(PROJECT_ROOT, 'models')\n","MODEL_FILENAME = 'vit_day3' # Base name for the file\n","\n","# Define a checkpoint callback to save the model weights (Task 2)\n","# The actual saved file will be vit_day3-vX.ckpt (PyTorch Lightning default)\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath=MODEL_SAVE_DIR,\n","    filename=MODEL_FILENAME,\n","    monitor='train_loss',\n","    mode='min',\n","    save_last=True,\n","    save_top_k=1, # Save only the best model\n","    verbose=True\n",")\n","\n","# Initialize Trainer\n","trainer = pl.Trainer(\n","    max_epochs=7,\n","    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n","    devices=1,\n","    callbacks=[checkpoint_callback],\n","    log_every_n_steps=50,\n","    # Use 16-mixed precision for faster training on GPU\n","    precision='16-mixed' if torch.cuda.is_available() else '32',\n",")\n","\n","print(f\"Trainer initialized for max {trainer.max_epochs} epochs.\")\n","print(\"Starting ViT training (Task 1)...\")\n","\n","# --- Run TRAINING for 5–7 epochs (main part of Task 1) ---\n","trainer.fit(vit_model, datamodule=dm)\n","\n","print(\"Training finished.\")\n","\n","# Task 2: Confirmation of saved weights\n","print(f\"Model weights saved to Drive. Best checkpoint path: {checkpoint_callback.best_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867,"referenced_widgets":["a349ca65034944a59c337168f8ed3d17","3e8d555b7fc147cfbff154326701a434","156885203ebe47c1a0f8382b270f6430","2322ab5927bd41be978c09f34d548902","9334bfb501124d9185e324ce4c112b24","e7ea23af41484247a61f6f10c2add01b","7e903fca54274b979cb9174b596abb9a","09ce91d5f9274b99b3be60513906fd77","72aedb80636e4e56acf8deb6ec16d2d3","54cee30c5b5a4bf5bb8d863c9d24022b","94da874064be446db79eae00f4337cf7"]},"id":"ABQ6R6yabY2G","outputId":"c92fd900-c8d4-4d7d-a557-42c97b260761","executionInfo":{"status":"ok","timestamp":1763557289418,"user_tz":-330,"elapsed":488172,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}}},"execution_count":25,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trainer initialized for max 7 epochs.\n","Starting ViT training (Task 1)...\n","Loading training dataset (Robust)...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name          | Type               | Params | Mode \n","-------------------------------------------------------------\n","0 | backbone      | VisionTransformer  | 21.7 M | train\n","1 | classifier    | Sequential         | 198 K  | train\n","2 | criterion     | CrossEntropyLoss   | 0      | train\n","3 | test_accuracy | MulticlassAccuracy | 0      | train\n","4 | test_f1       | MulticlassF1Score  | 0      | train\n","-------------------------------------------------------------\n","198 K     Trainable params\n","21.7 M    Non-trainable params\n","21.9 M    Total params\n","87.457    Total estimated model params size (MB)\n","284       Modules in train mode\n","0         Modules in eval mode\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Loading validation dataset (Robust)...\n","Dataset loaded successfully. Found 3 classes.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a349ca65034944a59c337168f8ed3d17","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stderr","text":["WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 529: 'train_loss' reached 0.75283 (best 0.75283), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 1058: 'train_loss' reached 0.66312 (best 0.66312), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 1587: 'train_loss' reached 0.63756 (best 0.63756), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 2116: 'train_loss' reached 0.62569 (best 0.62569), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 2645: 'train_loss' reached 0.61514 (best 0.61514), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 3174: 'train_loss' was not in top 1\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/ACCEPT/cast_ok_0_8016_jpeg.rf.d3cd5bc2eb139f71cb3351893fa0eece.jpg\n","WARNING:root:Skipping corrupted file: /content/drive/MyDrive/Hybrid_Project/data/train/SURFACE IMPERFECTION/cast_def_0_4835_jpeg.rf.ccef46934213e8ac012c57a0e60be0c4.jpg\n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 3703: 'train_loss' reached 0.61166 (best 0.61166), saving model to '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' as top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n"]},{"output_type":"stream","name":"stdout","text":["Training finished.\n","Model weights saved to Drive. Best checkpoint path: /content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt\n"]}]},{"cell_type":"code","source":["# %%\n","# -----------------------------------------------------------\n","# 5. Run Test Phase (Task 3)\n","# -----------------------------------------------------------\n","import json\n","import os\n","\n","print(\"Starting ViT Test Phase...\")\n","\n","# The best model path determined by the checkpoint callback is used.\n","BEST_MODEL_PATH = '/content/drive/MyDrive/Hybrid_Project/models/vit_day3-v1.ckpt' # Explicitly set based on output\n","\n","# Load the best model from the checkpoint\n","# The ViTModel class definition must be available (which it is)\n","vit_model_test = ViTModel.load_from_checkpoint(\n","    BEST_MODEL_PATH,\n","    num_classes=NUM_CLASSES # NUM_CLASSES should still be 3 from Code Block 2\n",")\n","\n","# Run the test loop using the same DataModule (dm)\n","test_results = trainer.test(vit_model_test, datamodule=dm)\n","\n","print(\"Test phase complete.\")\n","print(f\"Test Results: {test_results}\")\n","\n","# %%\n","# -----------------------------------------------------------\n","# 6. Save Test Results (Task 3)\n","# -----------------------------------------------------------\n","\n","RESULTS_FILE_PATH = os.path.join(PROJECT_ROOT, 'results', 'test_results_vit_day3.json')\n","\n","# The test_results is a list of dicts; we save the first element (the main results)\n","# The dictionary contains: test_loss, accuracy, and class_0_f1, class_1_f1, etc.\n","with open(RESULTS_FILE_PATH, 'w') as f:\n","    # We save the results from the first element of the list\n","    json.dump(test_results[0], f, indent=4)\n","\n","print(f\"Test results saved to: {RESULTS_FILE_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["1b1f50a244a0436d8dcd9c957d20331e","640ce9a3215c4c87b43865ec3b2fdf9d","574e04a16dd04bdea2b21d5772942d66","38cc69c4ef484e8a89c815ff26d2f751","05b1d60d9a2d45ca86cb552e4c786be7","926d49adada94f84bf0200936872a7d3","45e977b6d4e8424bbee8c93ffca4f5f9","88eb394c079647a897d6911697e73baf","c348d66f5b4b415dbccc1754f0695529","10bc3f1eabe24cbeb75b6fcf9ac233b4","899b313708b4471981a5b76badef8fdc"]},"id":"pvIq1Dt-NqL2","executionInfo":{"status":"ok","timestamp":1763557733591,"user_tz":-330,"elapsed":303563,"user":{"displayName":"NANDHA BIJU RSET","userId":"09849500797621619532"}},"outputId":"0e081cdd-d36f-4cda-dd29-69166d56d7e9"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting ViT Test Phase...\n","Loading training dataset (Robust)...\n","Loading validation dataset (Robust)...\n","Dataset loaded successfully. Found 3 classes.\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1f50a244a0436d8dcd9c957d20331e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8147208094596863    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       class_0_f1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8989361524581909    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       class_1_f1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m       class_2_f1        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7692307829856873    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5377506017684937    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8147208094596863     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        class_0_f1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8989361524581909     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        class_1_f1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">        class_2_f1         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7692307829856873     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5377506017684937     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test phase complete.\n","Test Results: [{'test_loss': 0.5377506017684937, 'accuracy': 0.8147208094596863, 'class_0_f1': 0.8989361524581909, 'class_1_f1': 0.0, 'class_2_f1': 0.7692307829856873}]\n","Test results saved to: /content/drive/MyDrive/Hybrid_Project/results/test_results_vit_day3.json\n"]}]}]}